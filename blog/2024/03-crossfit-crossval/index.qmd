---
title: "Visualizing cross-fitting and cross-validation for causal inference"
subtitle: > 
  A visual way to understand cross-fitting, double cross-fitting, and cross-validation and how to differentiate between them.
author: "Ehud Karavani"
date: 2024/12/30
date-modified: last-modified
bibliography: references.bib
image: ./double_crossfit-2.png
categories: 
  - causal inference
  - visualization
execute: 
  echo: true
  eval: false  # Just behave as a Python pseudo code
  freeze: auto
---

# Introduction
The integration of complex machine learning estimators with causal inference estimators is beneficial but not trivial.

It is beneficial because once we have complex high-dimensional data, where we can't just summarize the outcome each "cell" of the data (i.e., every combination of covariate levels), identification of the causal effect no longer solely relies on whether we where able to measure all confounders but also on whether we were able to capture the correct functional form between confounders, treatment and outcome (i.e., correct model specification). 
Machine learning (ML) techniques can therefore really broaden the range of functional forms, and therefore increase our faith that we were able to correctly specify the model. 

However, applying ML estimators opens a new front of modeling considerations like bias in effect estimations due to overfitting. 
Therefore, plugging complex ML estimators into causal estimators is not trivial and requires adaptations.
One such adaptation is the need to model both the treatment and the outcomes separately (like in TMLE or double/debias ML).
Another adaptation is out-of-sample estimation, which comes in different forms: cross-validation, cross-fitting, and double cross-fitting.
Cross validation, familiar to most ML practitioners is the same data partitioning scheme as cross-fitting.
Double cross-fitting introduces an additional 50:50 split within each fit-fold.
This post will try to make sense of these out-of-sample techniques visually.

Throughout this post I will use $X$ to denote covariates/confounders, $A$ for a treatment assignment, and $Y$ for the outcome. 
The treatment will be modeled with a function $\pi(X)$, and the outcome with the function $m(X)$ (or $m(X,A)$ in the case of AIPW and TMLE). 
Both will have a subscript $-k$ to specify the out-of-fit fold on which they predict on (with $K$ being 5 in total in this post).
While often in the causal inference literature, each such test fold will be used for an effect estimation that will later be aggregated across folds,
the overarching goal for us in this post will be to generate out-of-sample predictions for each observation in the dataset that will later be used estimate an effect once[^1].

[^1]: This is similar to how [CV-TMLE](https://biostats.bepress.com/ucbbiostat/paper273/)(@zheng2010asymptotic) estimates an effect using TMLE within each test data partition, 
while the is [an equivalent version](https://arxiv.org/abs/1811.04573)(@levy2018easy) in which TMLE is simply fed with test-data partition predictions (and the TMLE procedure is ran just once). 

# Cross-validation / cross-fitting
Cross-validation and cross-fitting apply the same data-partitioning scheme.
We split the data into $K$ folds, for each fold $k$ we predict using models that were fitted using data from the rest of the data ($\pi_{-k}$ and $m_{-k}$).

This is similar to generating predictions using Scikit-learn's `cross_val_predict`, making sure to align the folds to match for the treatment and outcome models.

```{python}
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.model_selection import cross_val_predict, KFold

kfold = KFold(n_splits=5, shuffle=True, random_state=0)
a_pred = cross_val_predict(GradientBoostingClassifier, X=X, y=a, cv=kfold)
y_pred = cross_val_predict(GradientBoostingRegressor, X=X, y=y, cv=kfold)
# Run DML using `a_pred` and `y_pred` for residualization.
```

Figure @fig-crossfit_crossval visualizes this process, in which data is partitioned into 5 folds, each assigned a unique color (left).
The middle two blocks each describe the data for the two models, treatment model $\pi_k$ and outcome model $m_k$. 
In each fold the test partition is depicted in dark grey, and the train fold are blended colors of the folds used to fit the model on the $k$-th train-test split. 
The right block depicts the out-of-sample prediction. 
For example, test-fold 1 (orange) is predicted using the model fitted on folds 2-5 (light blue, green, purple, dark blue; blended). 
Most importantly, the folds between the treatment and outcome models are completely aligned - for each test-partition, the treatment model and the outcome model were trained on the same complementary partitions.

:::{.column-page}
![A visual scheme for a 5-fold cross-validation/cross-fitting. Each data partition (fold, made of $X,A,Y$) is assigned a unique color. Five treatment models ($\pi_k$) and outcome models ($m_k$) are fitted on 4 folds, with the test-split depicted in dark grey, and the color of the train folds are blended. Finally, the propensity scores and outcome are predicted for the out-of-sample fold using the fitted models on the complementary train splits (depicted by the blended colors). Importantly, for each test-partition, the treatment model and the outcome model were trained on the same complementary partitions.](crossfit-crossval.png){#fig-crossfit_crossval}
:::

# Double cross-fitting
Appears

Decoupling the propensity
TODO: you need independence between folds, which you don't really get because how the training set overlap across folds. 
cross validation, within each train fold split 50:50 between treatment and outcome models

reference newey and robins

mention figure 1 in zivich

:::{.column-page}

![](double_crossfit-1.png){#fig-double_crossfit}

:::

# Repeated random partitioning





TODO: randomly repeating shuffles. the particular split of the data often changes the answer dependence on the particular division of the data into pieces




# Summary



# Appendix {.appendix}

:::{.column-page}

![](double_crossfit-2.png){#fig-double_crossfit_compact}

:::