<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ehud Karavani">
<meta name="dcterms.date" content="2018-05-05">

<title>Ehud Karavani - Applying Deep Learning to Genetic Prediction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/bar-chart-fill.svg" rel="icon" type="image/svg+xml">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/iconify-1.0.0-beta.2/iconify-icon.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Ehud Karavani - Applying Deep Learning to Genetic Prediction">
<meta property="og:description" content="What classical methods for obtaining polygenic (risk) scores lack, and how deep learning might help mitigated these shortcomings.">
<meta property="og:image" content="https://ehudkr.github.io/blog/2018/01-deep-learning-genetic-prediction/images/paste7.png">
<meta property="og:site-name" content="Ehud Karavani">
<meta name="twitter:title" content="Ehud Karavani - Applying Deep Learning to Genetic Prediction">
<meta name="twitter:description" content="What classical methods for obtaining polygenic (risk) scores lack, and how deep learning might help mitigated these shortcomings.">
<meta name="twitter:image" content="https://ehudkr.github.io/blog/2018/01-deep-learning-genetic-prediction/images/paste7.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Ehud Karavani</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../cv/index.html" rel="" target="">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../publications/index.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../materials/index.html" rel="" target="">
 <span class="menu-text">Materials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ehudk" rel="me" target="_new"><i class="bi bi-linkedin" role="img" aria-label="linkedin">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=KAzt_pYAAAAJ&amp;hl=en" rel="me" target="_new">
 <span class="menu-text"><iconify-icon inline="" icon="simple-icons:googlescholar" style="font-size: 1.25em;"></iconify-icon></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ehudkr" rel="me" target="_new"><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://medium.com/@ehudkr" rel="me" target="_new"><i class="bi bi-medium" role="img" aria-label="medium">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ehudkar" rel="me" target="_new"><i class="bi bi-twitter" role="img" aria-label="twitter">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://bsky.app/profile/ehudk.bsky.social" rel="me" target="_new">
 <span class="menu-text"><iconify-icon inline="" icon="fluent-emoji:blue-square"></iconify-icon></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://mastodon.social/@ehudk" rel="me" target="_new"><i class="bi bi-mastodon" role="img" aria-label="mastodon">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://stackoverflow.com/users/7708413/ehudk" rel="me" target="_new"><i class="bi bi-stack-overflow" role="img" aria-label="stack-overflow">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://discourse.datamethods.org/u/ehudk/summary" rel="me" target="_new">
 <span class="menu-text"><iconify-icon inline="" icon="simple-icons:discourse"></iconify-icon></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#experiments-and-upper-bounds-of-genetic-prediction" id="toc-experiments-and-upper-bounds-of-genetic-prediction" class="nav-link active" data-scroll-target="#experiments-and-upper-bounds-of-genetic-prediction">Experiments and upper bounds of genetic prediction</a></li>
  <li><a href="#formal-setting" id="toc-formal-setting" class="nav-link" data-scroll-target="#formal-setting">Formal setting</a></li>
  <li><a href="#how-is-it-done-today" id="toc-how-is-it-done-today" class="nav-link" data-scroll-target="#how-is-it-done-today">How is it done today</a></li>
  <li><a href="#the-proposed-method" id="toc-the-proposed-method" class="nav-link" data-scroll-target="#the-proposed-method">The proposed method</a></li>
  <li><a href="#discussion-2" id="toc-discussion-2" class="nav-link" data-scroll-target="#discussion-2">Discussion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/ehudkr/ehudkr.github.io/blob/main/blog/2018/01-deep-learning-genetic-prediction/index.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/ehudkr/ehudkr.github.io/edit/main/blog/2018/01-deep-learning-genetic-prediction/index.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/ehudkr/ehudkr.github.io/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Applying Deep Learning to Genetic Prediction</h1>
<p class="subtitle lead"></p><p>What classical methods for obtaining polygenic (risk) scores lack, and how deep learning might help mitigated these shortcomings.</p><p></p>
  <div class="quarto-categories">
    <div class="quarto-category">genetics</div>
    <div class="quarto-category">deep learning</div>
  </div>
  </div>


<!-- Adjusted from: https://github.com/quarto-dev/quarto-cli/blob/482a3cf7e9a9b42f62d351416a1e8234a4c6cd56/src/resources/formats/html/templates/title-metadata.html -->

<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ehud Karavani </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <!-- <div class="quarto-title-meta-heading" style="display: inline;">Published</div> -->
      <!-- <p style="display:inline"><a href=https://medium.com/ehudkr/improving-genetic-prediction-using-deep-learning-ae9f999036d0><i class="bi bi-medium"></i></a></p> -->
    <div class="quarto-title-meta-contents">
      <p class="date" style="display:inline">May 5, 2018</p> 
            <!-- Add medium icon if attribute exists -->
      <p style="display:inline"><a href="https://medium.com/ehudkr/improving-genetic-prediction-using-deep-learning-ae9f999036d0"><i class="bi bi-medium"></i></a></p>
          </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">December 16, 2023</p>
    </div>
  </div>
    
  </div>
  


</header>

<div id="medium-og" style="text-align: center">
<p><span style="text-align: center;">Originally published on <a href="https://medium.com/@ehudkr/improving-genetic-prediction-using-deep-learning-ae9f999036d0"><iconify-icon inline="" icon="simple-icons:medium"></iconify-icon> Medium</a>.</span></p>
</div>
<section id="experiments-and-upper-bounds-of-genetic-prediction" class="level3">
<h3 class="anchored" data-anchor-id="experiments-and-upper-bounds-of-genetic-prediction">Experiments and upper bounds of genetic prediction</h3>
<p>An organism can be defined by a set of traits (e.g.&nbsp;we can define a person using her height, IQ, predisposition for osteoporosis, etc.). The value of a given trait can be decomposed into two contributing factors: a genetic and non-genetic one (i.e., environmental). How much genetic factors contribute to the value of a given trait can be measured in a <a href="https://en.wikipedia.org/wiki/Twin_study">twin study</a>. Basically, taking identical twins (so they share almost identical DNA) and fraternal twins (so they are siblings but under a very similar environment) and comparing them. If the identical twins are more similar than the fraternal ones it means genetic plays a more important role in this trait than environmental.&nbsp;</p>
<p>We can further quantify the contribution of genetic influence. In height, for example, <a href="https://www.scientificamerican.com/article/how-much-of-human-height/">DNA determines ~70% of the contribution</a>. Roughly, that means that if we’ll try to predict one’s height using only her DNA we can be ~70% accurate. That also means that an orphan child adopted and raised by a tribe of basketball players can gain up to 30% more height than it would have if he’d grow up with he’s biological pro-golfers parents.</p>
<p>However, on the computational side, the best method is currently able to predict around 50% (See table 1 from <a href="https://www.nature.com/articles/ng.3097">this study</a>). These types of studies predicting traits from DNA are called genome-wide association studies (GWAS). They try to associate the contribution of each allele (i.e.&nbsp;a specific value in a specific location of the genome) to the desired phenotype (say, a physical trait or a risk for some condition).</p>
</section>
<section id="formal-setting" class="level3">
<h3 class="anchored" data-anchor-id="formal-setting">Formal setting</h3>
<section id="feature-space" class="level4">
<h4 class="anchored" data-anchor-id="feature-space">Feature space</h4>
<p>We begin with our feature-space — the DNA.&nbsp;<br>
DNA can be presented as a long linear strand over an alphabet of four characters: {A, C, G, T}.<br>
DNA has two problems preventing it being a good feature space:</p>
<ol type="1">
<li><p>It is unreasonably huge. <a href="https://www.ncbi.nlm.nih.gov/books/NBK21134/">A homo-sapiens has about 3.2 billion base-pairs</a> <a href="https://www.researchgate.net/post/Does_the_33_GB_of_the_human_genome_belong_to_one_set_of_chromosomes_23_chromosome_or_to_the_all_diploid_set_46_chromosome">in a single haplotype</a>, and since each of us has two chromosomes of each kind (thanks, mom and dad!), that means that each individual has 6.4⋅10⁹ features describing them. ImageNet, for comparison has 6.5⋅10⁴ features (not to mention we usually have far less people in a study than we have images, talking about <span class="math inline">\(p≪n\)</span>, right?).</p></li>
<li><p>It is not always consistent along different individuals. A small child can have a different length of DNA than her grandparent due to <a href="https://en.wikipedia.org/wiki/Telomere#Shortening">telomere shortening</a>, for example, but the main reason is actually because biology is hyper stochastic.&nbsp;<br>
This is way genomes are first aligned against an agreed representative genome, but that’s more modelling and one should be extra cautious aligning against a reference genome when actually looking for polymorphism.</p></li>
</ol>
<p>We overcome these problems physically and not computationally — we don’t use the entire genome of an individual, but rather sample <span class="math inline">\(M\)</span> variants (i.e.&nbsp;genomic locations)from it, where <span class="math inline">\(M\)</span> is about 250–500k<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. This solves (1) by reducing dimensionality (you may think of it as a sort of random projection) and solves (2) by aligning our feature space across individuals.</p>
<p>Now, you may (and should) be a bit upset about this coarse treating of data, thinking “what if we just threw away the specific variant responsible for happiness? Now we never gonna know its effect!”. To which I’ll reply by saying that not all is lost. Variants which lie in close proximity on the DNA strand tend to “stick together” (known as <em>linkage disequilibrium</em>). Even if we don’t have the variant of effect, there’s a high probability we have its neighbor, and since they are conserved together — this neighbor can serve as hatch to the causal one. This is also why it is called an <strong><em>association</em></strong> study — it has no causal guarantees about the variants.</p>
<p>This method is less than perfect and there are other types of studies, such as whole-genome ones, to overcome this obstacle, but for the sake of this field, we stick to the plan as it is reasonable enough<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</section>
<section id="sample" class="level4">
<h4 class="anchored" data-anchor-id="sample">Sample</h4>
<p>Now that we defined our data measurements, we can go and recruit people to gather data from. We sample <span class="math inline">\(N\)</span> subjects from some population.<br>
The population of choice (namely, how diverse it is), deserves a post (or several) for itself, but for now we’ll take it for granted.</p>
</section>
<section id="the-data" class="level4">
<h4 class="anchored" data-anchor-id="the-data">The data</h4>
<p>We can present our data as a matrix <span class="math inline">\(G\)</span> of <span class="math inline">\(N \times M\)</span>, where each cell contains one out of 16 possible combinations of nucleotides. Each genomic location has two copies (one from each chromosome), so it can have any of the 4 possibilities in each one of the copies, and that amounts to a total of 16 options.<br>
This data matrix is usually captured as follows:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Usual raw data&nbsp;matrix.</figcaption>
</figure>
</div>
<p>Those of you who are sharp-sighted may notice “well, this is very phonetic, we need to make it numbers and go start predicting!”.</p>
<p>Very well, let us begin our journey.</p>
</section>
</section>
<section id="how-is-it-done-today" class="level3">
<h3 class="anchored" data-anchor-id="how-is-it-done-today">How is it done today</h3>
<section id="data-transformation" class="level4">
<h4 class="anchored" data-anchor-id="data-transformation">Data transformation</h4>
<p>First thing, we make another assumption: we assume each variant can contain at most two different values. That is, each column in our data matrix <span class="math inline">\(G\)</span> is restricted to have a maximum of two unique nucleotides. In our example above, <em>variant 1</em> is restricted only to A or G and <em>variant 2</em> only to C or A. This is also known as <em>Single</em> Nucleotide Polymorphism (SNP).</p>
<p>Once we’ve restricted ourselves to two values per column, we can calculate their prevalence in that specific variant across the dataset. The nucleotide that is less abundant will be called the <em>minor allele</em> and the one more abundant… wait for it… the <em>major allele</em>, because geneticists tend to focus on rare alleles (rare genetic disease must be caused by rare alleles). Wearing the hat of a geneticist, we’ll continue with our focus on the minor allele.</p>
<p>We denote the frequency of the minor allele in some variant <span class="math inline">\(j\)</span> as <span class="math inline">\(p_j\)</span>, which we can think of as the probability to get that minor allele in a person. Since we have two chromosomes, we have two trials to try and get it. Therefore, for a given individual <span class="math inline">\(i\)</span>, the number of minor alleles in her variant <span class="math inline">\(j\)</span> can be modeled as <span class="math inline">\(g_{ij} \sim Bin(2, p_j)\)</span>.</p>
<p>This way, if you have two minor alleles you’d have “high energy” (i.e.&nbsp;a value of 2 instead of 0 or 1). Moreover, the rarer the allele, the more an individual with it will “stand out” from the other individuals in the sample. Remember, geneticists search for these irregular and rare appearances of alleles to explain the presence of irregular and rare traits.<br>
Transforming our <span class="math inline">\(G\)</span> from above give us the following design matrix:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-3.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Design matrix under classical methods.</figcaption>
</figure>
</div>
</section>
<section id="prediction-methods" class="level4">
<h4 class="anchored" data-anchor-id="prediction-methods">Prediction methods</h4>
<p>Once we defined our data matrix, we would usually regress (either linear or logistic) to obtain a model that describes the relation between these exogenous variables — the number of minor alleles in every variant, and our endogenous variable that is the trait of interest.</p>
<p>To account for these still large number of features, we can apply several tools. I’ll try to name few of the more known strategies I know of, but I’m in no position of making a comprehensive list. I will say, that they all try to find a smaller set of variants that explain the trait. The first method does it implicitly when regularizing the model, but the following two are more straightforward about it.</p>
<ol type="1">
<li><p><strong>LASSO</strong> explicitly regularizes the parameters being learned by shrinking them towards 0. It assumes each variant has a tiny contribution unless proven otherwise.</p></li>
<li><p><strong>P-value cutoff</strong>. We can obtain from the regression a significance level for each weight (i.e.&nbsp;each variant). Correcting for multiple-tests aside, we can choose to discard all the variants with high p-value, as we claim they are not of interest to our specific problem (i.e.&nbsp;not unique for predicting our phenotype)<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p></li>
<li><p><strong>LD clumping</strong>. We mentioned before that DNA segments tend to “stick together”. This was how we rationalized the use of DNA markers instead of an entire genome. But what if this set of markers is still redundant. Maybe if we’d look at some small window, the signal will be so consistent that we could just pick one representor variant (or a handful) from that window. There can be different tactics for choosing a representor in a given window, we can choose them based on their p-value (it’s like (2) if the “window” would be the entire genome), or by their <em>R²</em> value (i.e.&nbsp;how they correlate in that window). We can use a cutoff, or choose <em>k</em> best, and we’d need to adjust for window size based on how crowded our variants are.</p></li>
</ol>
<p>My main takeaway on this, is that since DNA has a structure, the columns in our matrix have high co-linearity, which we should account for (either in penalized regression or in discarding subsets of the columns).</p>
<p>Of course, there are other techniques like using Bayesian statistics and accounting for priors that reduce false positive variants, but overall, these heuristics deliver ok thus far.</p>
</section>
<section id="discussion" class="level4">
<h4 class="anchored" data-anchor-id="discussion">Discussion</h4>
<p>One big advantage of this strategy is that it is backed up by solid a statistical framework. At least during the modeling. However, this backup might do more harm than good when getting to prediction. Namely, the heuristic preprocessing.<br>
On the other side, I can think of several disadvantages:</p>
<ol type="1">
<li><p><strong>Restricting each column to two variants</strong> might reduce the variability (or the full expressive range) of the data. It might even paint a non-realistic image of the world with the entire modeling strategy is built on it.<br>
Historically the arrays used for genotyping were designed to be binary (they would omit either red or green light), and it corresponds with the naive research design claiming we’re all the same unless “a lightning stroke” in that genomic location and mutated it to be different. But what if a lightning had struck twice in the same spot? <em>Multiple</em> Nucleotide Polymorphisms (MNP as opposed to SNP) are becoming more prevalent as we move from old genotyping techniques to modern DNA sequencing that is more expressive and can capture a more realistic snapshot of one’s DNA.</p></li>
<li><p><strong>Sex chromosome cannot be modeled</strong>. Since the entire scheme is based on a two-trial binomial distribution, you can’t model males’ sex chromosome. Females have two X chromosomes, making it another diploid chromosome. However, males have one X and one Y that do not fully correspond to one another, so you can’t apply a two-trial binomial test there. [That’s half the population we’re neglecting]. As a result, it is not very common to model sex chromosome, so for my understanding, most of the studies are based mostly on autosomal chromosomes.<br>
How can you account for the difference between males’ and females’ height if you don’t model the genetic differences between males and females.</p></li>
<li><p>It might not be simple to apply the model in a different study. Since it is a linear model, it has a weight for each variant. But what if another study used slightly different genetic markers? We wouldn’t be able to account for them. Variants in our study would be discarded and we would need to ignore variants in the model that we don’t have. Nothing promises that the sets of markers from different studies would perfectly intersect.<br>
[A common solution is to impute genomes, but that only adds more assumptions and uncertain modeling to the process]</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-5.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Example of trait differences between males and females. How can we account for sex-chromosome-based traits if we don’t measure&nbsp;them?</figcaption>
</figure>
</div>
</section>
</section>
<section id="the-proposed-method" class="level3">
<h3 class="anchored" data-anchor-id="the-proposed-method">The proposed method</h3>
<p>I propose a deep learning scheme to cope with the cons above.</p>
<section id="data-transformation-1" class="level4">
<h4 class="anchored" data-anchor-id="data-transformation-1">Data transformation</h4>
<p>We begin with as function <span class="math inline">\(O\)</span> that encodes each nucleotide as a one-hot vector (the order is by the English alphabet for consistency):</p>
<p><span class="math display">\[
O(A): \begin{bmatrix}1 \\ 0 \\ 0 \\0\end{bmatrix}, \;\;
O(C): \begin{bmatrix}0 \\ 1 \\ 0 \\0\end{bmatrix}, \;\;
O(G): \begin{bmatrix}0 \\ 0 \\ 1 \\0\end{bmatrix}, \;\;
O(T): \begin{bmatrix}0 \\ 0 \\ 0 \\1\end{bmatrix}
\]</span></p>
<p>For each individual, we encode their two alleles as the sum of the above encoding, creating a sort of a two-hot encoding</p>
<p><span class="math display">\[
O(g_{ij})=O(g_{ij}^{(1)})+O(g_{ij}^{(2)})
\]</span></p>
<p>For example, let’s see a bi-allelic and mono-allelic instances:</p>
<p><span class="math display">\[
O(GA)=O(G)+O(A)=\begin{bmatrix}0 \\ 0 \\ 1 \\0\end{bmatrix} + \begin{bmatrix}1 \\ 0 \\ 0 \\0\end{bmatrix} = \begin{bmatrix}1 \\ 0 \\ 1 \\0\end{bmatrix}, \; \;
O(CC)=O(C)+O(C)=\begin{bmatrix}0 \\ 1 \\ 0 \\0\end{bmatrix} + \begin{bmatrix}0 \\ 1 \\ 0 \\0\end{bmatrix} = \begin{bmatrix}0 \\ 2 \\ 0 \\0\end{bmatrix}.
\]</span>This way, each individual <span class="math inline">\(i\)</span> can be presented as a <span class="math inline">\(4 \times M\)</span> matrix and the dataset as a <span class="math inline">\(4 \times M \times N\)</span> tensor. The rows from above are represented as:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-6.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">The encoding of the first two rows from the data matrix&nbsp;above.</figcaption>
</figure>
</div>
<p>Stacking these matrices composes our design tensor:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 51.2%;justify-content: center;">
<p><img src="images/paste-2.png" class="img-fluid" width="420"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 48.8%;justify-content: center;">
<p><img src="images/paste-4.png" class="img-fluid" width="400"></p>
</div>
</div>
</div>
<p>We can transpose the dimensions as one’s find convenient. Namely, treating each individual as a <span class="math inline">\(1 \times M \times 4\)</span> tensor (treating the genotype as “channels”) will allow as to think of the dataset again as an <span class="math inline">\(N \times M\)</span> “matrix” only with each “cell” being of depth 4.</p>
</section>
<section id="prediction-methods-1" class="level4">
<h4 class="anchored" data-anchor-id="prediction-methods-1">Prediction methods</h4>
<p>Now we are left to decide what will be a good network architecture for the problem.<br>
I suggest a convolutional-neural-network-based solution due to the following characteristics:</p>
<p><strong>First</strong>, convolutions fit this problem since our variants are more correlated the closer they are (highly local correlations) so they can accommodate for linkage disequilibrium (by assessing a rolling-window of the genome). Again, LD is what allowed us to avoid using the entire genome in the first place and it is the core idea behind the widespread LD-clumping method.</p>
<p><strong>Second</strong>, each chromosome gets a separate network (they can have the same architecture, though). Since the number of chromosomes is constant, we can allow ourselves to hard-code it into our model. This has two (and a half) advantages:</p>
<ol type="1">
<li><p>It allows to obtain different information from different chromosomes, with different chromosomes having different genes, contributing to different properties of the individuals.</p></li>
<li><p>We don’t want to “leak” information between chromosomes. The order of chromosomes is arbitrary (chromosome 1 is just the largest and 22 is the smallest). Since convolutions applied on a sequence-like data, we don’t want to apply it on an artificial sequence, like the end of chromosome 1 and the beginning of chromosome 2. <em>This sharing of weights has no biological meaning</em>.</p></li>
<li><p>Not that it’s a good reason by itself, but it can help parallelism of computation and possibly boost some things up.</p></li>
</ol>
<p><strong>Third</strong>, each kernel is of size <span class="math inline">\(l\)</span>, where <span class="math inline">\(l\)</span> is a characteristic length of linkage disequilibrium window. This value can be empirically calculated from the train data before setting the model by simply looking at the correlation matrix of variants-over-variants. This matrix will have a general structure of a diagonal block matrix. The size of that block would be a good guess as for the size of the needed window.&nbsp;<br>
Note that in order to compute this correlation matrix, we would need to encode each individual as a vector, rather than a matrix. This is only for the purpose of figuring out a reasonable window size, so no need to get super fancy in the coding scheme:</p>
<ol type="1">
<li><p>The simplest way to pull it would be: {<em>A: 0, C: 1, G: 2, T: 3</em>}.</p></li>
<li><p>A more sophisticated scheme would be to group purine and pyrimidines at the other sides of the zero: {<em>C: -2, T: -1, A: 1, G: 2</em>}. Doing so, the Pearson correlation would “punish” less for transitions and more for transversions (<a href="https://en.wikipedia.org/wiki/Transition_%28genetics%29">explanation</a>).</p></li>
</ol>
<p>Not to mention that we can go full bananas and build an Inception-like architecture that uses different sizes of kernels (say <span class="math inline">\(l^{(1)}, l^{(2)}, l^{(3)}...\)</span>) and then concatenate and weight them (What <a href="https://arxiv.org/abs/1409.4842">the Inception paper refers to as <em>filter concatenation</em></a>).</p>
<p><strong>Forth</strong>, we concatenate the different latent-vectors for the different chromosomes. We apply one or more fully-connected layers and then an output layer (which varies depending on the problem).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/paste-7.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">A diagram depicting the suggested model <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</figcaption>
</figure>
</div>
</section>
<section id="discussion-1" class="level4">
<h4 class="anchored" data-anchor-id="discussion-1">Discussion</h4>
<p>Let’s see how this method overcomes the disadvantages of the classical approach:</p>
<ol type="1">
<li><p><strong>Not restricting variants to having only two alleles.</strong><br>
Basing our representation on one hot encoding does not limit the number of unique nucleotides we allow a single variant to have.</p></li>
<li><p><strong>Sex chromosomes can be easily modeled.</strong><br>
Females will have their X chromosomes transformed like the rest of their autosomal chromosomes (since they have two matching copies of it). Their Y chromosome will just be all zeros.<br>
Males will have their X and Y chromosomes encoded in a purely one hot measure. Since they don’t have two corresponding copies, they have no two alleles two sum their encoding in a given variant, leaving them with a simple one-hot encoding (instead of the “two-hot” we discussed for autosomal chromosomes).<br>
This is appropriate since there is indeed less sources of signal for sex chromosomes (with males having only one copy of each and females “having no signal at all for their Y chromosome”). The learning model can compensate for that, weighting the sex chromosomes accordingly.</p></li>
<li><p><strong>Generalization of the model to different studies</strong> can be achieved through <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer-learning</a>, even when the input data is slightly different. These tactics are common in the field of computer vision, where, for example, <a href="https://arxiv.org/abs/1512.03385">ResNet models</a> that <a href="https://arxiv.org/abs/1706.09092">were trained on natural images, can be only slightly adjusted to work on medical images</a>.<br>
I hypothesize that a good model will capture elements of the genetic architecture, which can be transferred to other input-data even if the new variants are not the exact same one as before, but of proximity to them.<br>
It also allows for <strong>absolute data coding</strong> that does not differ between studies. If the source study has a distribution of, say, 40:60 A to G in a genomic location and a downstream study (utilizing the results of the source study) has 60:40 A to G they will have different nucleotides being the minor/major alleles. The two studies will have the same design-matrix, but it will mean two different things since the coding of the design matrix is relative to the data-set at hand (less frequent allele) and not an absolute one (all the nucleotides).</p></li>
</ol>
<p>Another advantage is allowing the modeling to <strong>account for uncertainty of the sequence machine</strong>. It is not very rare for sequence machines to output codes that translate to “not sure whether A or G”. This cannot be represented in the classical representation (since they won’t happen across the entire sample, but only to <em>very few</em> individuals in each variant), but we can account for that using “half-hot” encoding.<br>
For example, if the sequencer is not sure of the exact nucleotide but certain it’s a purine (A or G), we can encode it as <span class="math inline">\(0.5 \cdot (O(A)+O(G))\)</span><em>.</em> In genomics, <em>I</em> is usually denoted as the sequencer’s output when uncertain which of the purine nucleotides it observed in one allele. The coding scheme can deal this uncertainty as follows:</p>
<p><span class="math display">\[
O(IC)=O(I)+O(C)=\begin{bmatrix}0.5 \\ 0 \\ 0.5 \\0\end{bmatrix} + \begin{bmatrix}0 \\ 1 \\ 0 \\0\end{bmatrix} = \begin{bmatrix}0.5 \\ 1 \\ 0.5 \\0\end{bmatrix}, \; \;
O(IG)=O(I)+O(G)=\begin{bmatrix}0.5 \\ 0 \\ 0.5 \\0\end{bmatrix} + \begin{bmatrix}0 \\ 0 \\ 1 \\0\end{bmatrix} = \begin{bmatrix}0.5 \\ 0 \\ 1.5 \\0\end{bmatrix}.
\]</span></p>
<p>Two cons I can think of, which are common for all neural-net models, are:</p>
<ol type="1">
<li><p><strong>Lack of interpretability.</strong> Trait prediction can have grave consequences to people (think of a person discovering her risk for some disorder), and humans are deterred from computer models they can’t understand deciding in fields currently controlled by humans (a good analogous are autonomous cars). However, my opinion is to emphasize that <em>this is an association study</em>, not a causal one. We’re only interested in the prediction and if obfuscate models perform better, so be it.</p></li>
<li><p><strong>Lack of rigorous mathematical basis.</strong> To which I would say that we had lost it in the classical method as well the moment we began applying pre and post processing heuristics.</p></li>
</ol>
</section>
</section>
<section id="discussion-2" class="level3">
<h3 class="anchored" data-anchor-id="discussion-2">Discussion</h3>
<p>I presented a modeling system that, for the best of my knowledge, is a novel way of approaching the task of trait prediction based on genetic information. It uses neural networks for the task, a type of machine learning models that gained much popularity in recent years due to an increase in the amount of data and in computation power.<br>
Deep learning allows us to reduce the need for domain-expert data preprocessing by using its vast expressive power for functional form. This transition happened in computer vision and later in natural language processing, so it’s worth a try on genomic data as well.</p>
<p>Examples and code will accumulate on <a href="https://github.com/ehudkr/Deep-PGS">my GitHub repository <iconify-icon inline="" icon="simple-icons:github"></iconify-icon></a> as I progress with the project (though navigating between work and thesis leaves me with little time for side projects). Promise to keep you updated.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>still looking at this cute little ImageNet feature space.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>What is science if not baby-stepping all the way to the moon.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>P-value-based variable selection strategies are bad, see <a href="https://doi.org/10.1016/0895-4356(96)00025-X">Sun, Shook, and Kay</a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><em>It may be interesting to evaluate the model’s performance when different chromosomes will share some of the deeper convolutions. Namely, replacing the DNN box in the next figure with another CNN.</em><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/ehudkr\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>