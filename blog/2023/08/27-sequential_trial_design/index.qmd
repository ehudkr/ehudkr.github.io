---
title: Sequential trial design for causal inference
subtitle: >
  Aligning time-zero TODO
author: "Ehud Karavani"
date: 2023/08/27
date-modified: last-modified
bibliography: references.bib
categories: 
  - causal inference
  - study design
---

## Introduction
I'm not special, so I've spent a lot of time addressing confounding bias.
I even created and still maintain an open-source Python package whose main focus is flexible causal inference modeling ([`pip install causallib`](https://github.com/IBM/causallib)). 
There's a place to discuss why confounding bias is the most popular bias,
but this blog post is not it.
Maybe at some other time.

Actually, there's some compelling evidence (well, at least anecdotal) that confounding bias has less of a biasing effect than what one would expect.
One example is @garcia2017value
examining the effect of colorectal cancer screening on colorectal cancer incidence.
It showed the same survival curves for treatment and control units
when adjusting and not adjusting for confounding factors.
This, in and of itself, is a poor evidence, 
but the exact same shape of survival curves also appeared in @bretthauer2022effect,
an RCT examing the exact same question.
This suggests that confounding bias did not affect the observational study.[^1]

[^1]: A similar phenomenon was also observed in @hernan2008observational,
finding similar hazard ratios (in terms of point estimation and confidence intervals) between adjusted and unadjusted estimates, 
suggesting the cause of discrepency between previous observational studies (even using the same data as they did) and RCTs was not confounding bias but rather the mysterious bias which is the subject of this blog post.

### I have _zero_ time for this bias
This bias originates from improperly setting the _time-zero_.
Time zero (or "index date") is the point in time which splits the baseline period from the follow-up period.
History from future, retrospectively speaking.
It usually the time in which treatment is initiated, 
and therefore the point in time from which we look backward to obtain historical data (baseline covariates) 
and look forward to gather follow-up data (outcomes).  
As such, to properly set up time zero, three things must align:

1. The subject must meet the eligibility criteria
1. "Treatment" must be assigned
1. Outcomes are beginning to be counted. 

Learning causal inference, we are used to getting datasets with nice and percise binary treatment variables and covariates.
But where did these come from?
People's lives are not cross sectional, they are a trajectory through time.
So there are lots of design decisions in order to squeeze all of it into tabular form.
Having longitudinal data makes it more possible, but not more easy.
How do we decide how to assign a person into either treatment groups (or not at all if not eligible).

Given this presentation, you might see why active-comparator designs are so appealing.
It is more straightforward to compare to active treatments head-to-head,
since we just define the first treatment initiation of each drug (the two groups) as our time zero.

The trickier part is when we want to design a study to compare treatment initators with _non-users_.
This is often of interest in pragmatic trials.
What is the index date for someone who just lived their life never getting treated?
Non-initators have no point in time where they start treatment,
making it harder to align this non-existing "treatment assignment" to the follow-up and eligibilty. 

This often leads to comparing either persistent users
or those who taken the drug at some time (i.e., _all_ or _any_), 
to those who never used it.
This study design does very little in informing physicians how to act on the patient they are currently facing.
_"Take this drug and if you survive the next 5 years (i.e., become a persistent user),_ 
_then you will reduce your risk by x percent"_ 
does not inspire much confidence 
and is not very helpful for the patient who is living now in the present and not five years into the future.[^2]

[^2]: Furthermore, I believe this discrepancy in how to define treatment groups, 
namely, how to define the $1$ and $0$ in $Y^1$ and $Y^0$, 
boils down to the causal consistency assumptions.
Defining a poor treatment mechanism in the study design means the outcome one observes in their data ($E[Y|A=a]$) will not equal the hypothetical outcome they care about ($E[Y^a]$).

## Sequential trial design
So how can we force the alignment of eligibility, treatment initiation, and follow-up into a proper time zero?

### A single "sequential" trial

One simple approach is to use calendar time. 
Set the time-zero to a specific date.
Say, for instance, January 1st, 2020.
This will be the point in time splitting history from future.
Keep whoever is eligibile to participate at this date, discard the rest;
data from before this date are the baseline covariates;
data from this date forward is the follow-up;
and whoever got treated on this date is considered in the treatment group, the rest are controls.

Individuals treated before January 1st are probably ineligible 
(most study designs might enforce participants to be treatment naive).
Individuals treated after January 1st are considered controls,
because time-zero is set at January 1st, not the future.
Though a per-protocol analysis might decide to censor them from follow-up because they deviated from their original (control) assignment.
This creates a design that answers a question of treat now vs. don't treat now (but possible treat later).

However, this single trial is too naive and not very efficient.
We miss all the treated individuals in the past and in the future.
There might even not be anyone treated on January 1st. 
We throw away a lot of information. 
That's a big blow to statistical power.

### A sequence of sequential trials

Therefore, a natural extension would be to just repeat the process.
Repeat it for January 2nd, 2020, for January 3rd, 2020, for January 4th, and so forth.
For each time point we:

1. Consider whoever meets the eligibility criteria and discard the rest,
1. Set the treatment indicator based on who got treated,
1. Extract baseline covariates prior to that time point,
1. Extract outcome information from that time onwards. 

![An illustration of the sequential trial process at a data-set level[^5]. At each time $t$ (starting with $t=0$, like Jan 1st), we check whoever is eligible and assign them to their appropriate treatment groups according to their treatmeent status at that time. At the next time step ($t=1$ or Jan 2nd), the pool of eligible individuals can change in several ways: 1) treated individuals from the past are probably no longer eligible, at least not before some washout period passes; 2) eligible people can become ineligible regardless of their past treatment status (e.g., they can turn 65 and no long fit the inclusion criteria). 3) Likewise, ineligible people from the past can become eligible if they suddenly fit the criteria (e.g., an individual can turn 18 at this time and become eligible). At each time we collect baseline and follow-up data according to the study design relative to this index date. This process repeates for all available time steps.](pop_level_process.png)

[^5]: This also illustrates why sequential trials may be sometimes called "nested" trials. 
This is because, in some common and simple settings, the trial at time $t$ (eligible people at time $t$) are _nested_ within the controls at time $t-1$.
However I think "nested trials" has a different meaning in the RCT landscape, so "sequential trials" is both more general and non-taken.
 
The way I imagine this process is that we have stencil-like mold, 
defined by our eligibility criteria,
from which we funnel observations like a strainer.
We go to January 1st, put the stencil-strainer, shake the database and filter only eligible individuals at the time. 
We then go to January 2nd, filter; 
and so on and so forth,
rinse and repeat.
A moving window through time, only that window is specially shaped by the eligibilty criteria. 

This means a single person can have multiple records (entries, or rows) in the dataset.
One for each trial (time-zero).

We can see this illustrated below with a person's timeline and its corresponding person-time tabular form.
In this study design, baseline covariates are taken 4 time steps relative to time-zero (e.g., 2 years prior to time-zero), 
and follow-up is taken 4 time steps starting time zero (e.g., outcome within 2 years).
Thus, the covariate profile changes as time-zero progresses.
At times 4-7, üèä‚Äç‚ôÇÔ∏è is included as it is within the baseline period dictated by the study design, but it is no longer counted in time 8.
Similarly, the outcome üöë is not observed at time 4, only starting at time 5.[^3]
To make things more explicitly, I also indicate eligibility; 
in this example, the study design requires participant to no been treated in the last 4 time-steps (treatment-naive), 
and so at times 7 and 8 the person is no longer eligibile as they were treated in time 6.[^4] 

![An illustration of a person timeline and how its corrsponding person-time tabular form. It shows multiple time-zeros set from time 4 throughout time 8 (think Jan 1st to Jan 4th from above). Different time-zeros have different covariate (üèä‚Äç‚ôÇÔ∏è) profile, different outcome (üöë) based on the moving follow-up window, and - although that person is treated (üíä) - they are not always considered as such.](single_person_time_moving_window.png)


[^3]: In time-to-event settings, the follow-up window is often as long as can be possibly observed, avoiding explicitly stating a follow-up timeframe.
In such scenarios, we can see the time to outcome (üöë) decreases as time-zero progresses.
![](single_person_time_moving_window_survival.png)

[^4]: First, note that they might also be inelgible because they don't have sufficient follow-up. 
Second, that person may also be ineligible at time 10 as they are no longer outcome-naive, too.


### A control explosion
Often, getting treatment is rarer than not getting treated. 
This imbalance is not inherently important, but can lead to some difficulties in practice.
Looking at the resulting dataset above, we see that sequential trials exacerbate this even further since even the treated individuals contribute (even more) non-treated rows, 
all the while never-treated individuals just multiply throughout time.

This control group inflation can be undesireable in practice.
It increases demand of computate resources, both in terms of memory and runtime. 
While not necessarily contributing enough information to justify it.
Statistical power is determined by the smallest group, anyway; 
and, while I don't know how to formally extend this argument into a repetaed-measurement setting,
I have an intuition that dozens and dozens of duplicate (and near-duplicate) records hit the diminishing returns curve somewhat quickly.

There are several valid strategies to deal with settings where eligibility criteria is met multiple times per person, resulting in cambrian-like explosion of controls records. 

First, we can just randomly subsample a fixed sample (e.g., 10%) from all the controls records from our dataset (@dickerman2019avoidable).
Since this blindly regards person and time information, it can have some unintended consequences like discarding entire time steps or individuals by some unfortunate random chance.
This can reduce variability in the dataset and hurt the infromation content of it.  
Fortunately, this can be easily solvable by forcing some structure on the discarding, like stratified sampling by time-steps and/or person IDs.

We can take this structural subsampling a step forward and force a single entry per-person, i.e., reduce it to a single eligibile record per person. 
When doing so, it is important to reduce it without taking strict advantage of "future infromation", namely by the treatment and outcome status of people's timeline. 
Two common ways are taking the first eligibility record per-person, or take one randomly (@hernan2016using).
Both are valid, non-biasing approaches, but they suffer from similar disadvantages presented above when randomly subsampling controls.
Namely, they can discard more useful infromation and keep more redundant infromation instead.
Specifically, they can blindly discard treatment records, which can be very precious. 
In reasonable cases where a treated person-time is not at treated at first eligibile time, 
or in cases where it simply bee been randomly discarded. 
As said above, treated person-time records are few to begin with, and reducing them the size of the treatment group even further reduces important statistical power unnecessarily. 

A forth option that maximizes the size of the (smaller) treatment group is a combined approach:
first, gather all the treated person-time records; 
and second, take first (or random) eligibility time per-person (@garcia2017value).
This is basically a different view of the first approach.
Both first fix (or take) all the treated person-times and then subsample just the control person-times.
Only here, the subsampling is further structured to keep one record per person (including individuals who are at some point treated) 
by determinstic subsampling (taking records at first eligibilty time)
or random subsampling (taking a random record from all eligible times of an individual).

![Illustration of the four strategies for dealing with the inflation of control person-times in multiple eligibility settings. It describes 3 people: A, B, and C and their treatment status over 5 time steps. First, using all person-times[^6] from which we can derive the rest. Second, first eligibilty only, where B1, A1, and C2 participate (note C1 is ineligible in this example). Third, a random eligibility time per person. Note that in both cases we lose A3 as a treated unit.  Forth, a mixed approach where we take all treated person-times _and_ 1st eligibilty time. Lastly, a fifth strategy taking all treated person-times and randomly sampling a fixed proportions from the controls is not showed.](multiple_eligibility.png)

[^6]: Note time 2 (Jan 2nd) may be redundant as it containd only control units. 
If time has some effect --- i.e., people at time $t$ might not be fully exchangeable with people at time $t^*$ --- then not having any comparable treated units at time 2 might violate a positiity (overlap) requirement. 
Thus time steps with all-controls may be further discarded in the preprocess step (drop the rows) or in the analytic step (e.g., apply exact matching on the trial ID [time step] and consequently discard such records).

In the mixed approaches, it is important to choose control person-times while ignoring treatment indication in a person's timeline.
For instance, in the example above, it might be tempting to discard control trials of person A, because person A is eventually treated.
Or, put differently, after selecting all the treated person-times, select a subsample of person-times controls while excluding people chosen in the treated person-times.
However, this can bias the analysis as it will create a control group that is, by construction, never-treated;
and never-treated might not be a comparable control for incidence users we care about (@garcia2017value).

#### Contemporary controls vs. self controls
As mention above, using all person-times can create computational strains and inefficiencies. 
All while in single-eligibility designs we might discard precious information.
Mixed approaches where we first select all treated person-times is a good middle ground solution, but there is no free lunch.

We originally perform a trial at each time step.
Looking at each trial independently, we adjust for time confounding as each treated person at that time has corresponding contemporary controls. 
However, when we dillute the controls (and the mixed approach of all-treated plus 1st eligibilty time is the most extreme approach), 
we reduce the weight of those contemporary controls.

Instead, vieweing the dataset as a whole, we increase the weight of self controls.
This is because for each person treated not at first eligibilty time we will have, by construction, two instances - one as treated and one as control.
When we discard records of other people from that time step, because this is not their first eligibility time, we reduce the relative weight (number) of contemporary controls and, by definition, increase the relative weight of the first eligible control person-times of those later treated. 

To simplify with the example above, in the all person-time approach, A3 is controlled by both its past self (A1) and a contemporary record (C3). 
When we go to the mixed approach, we drop C3, making A1 the sole control for A3.
Therefore, we reduced the relative weight of contemrporary controls (at time 3) and increased the relative weight of self-controls.

This can create bias if person $i$ at time $t$ is not exchangeable with itself (person $i$) at time $t^*$.  \
This is quite reasonably hold, as people might have trend overtime, like disease progression status.
Furthermore, if this progression is not captured by the covariates, it can create confounding bias (time confounding).
Therefore, another cosideration should be to check for such cases, and, following footnote [^6], keep trial ID in mind when adjusting and make sure every time-step can act as a quasi-dependent trial.


## Discussion

### Immortal (bias) Combat
Immortal time bias is when participants of a cohort cannot, by construction, experience the outcome during some period of the follow-up time[^7].
It usually happens when the researcher fails to align the cohort entry time (eligibility time) with the time of getting the treatment (time zero). 
If theresearcher classifies that individual as treated, and start counting the outcome from cohort entry - even though they are not treated at the start of eligibility - it necessarily means that that person did not (and couldn't have) experience the outcome in the time period between eligibility and time of actual being treated.
If you're very infamiliar with immortal time bias, I suggest going over its [entry in the Catalog of Bias website](https://catalogofbias.org/biases/immortal-time-bias).

[^7]: It is called "immortal" since often that outcome is death. 
So if one _cannot_ experience death for a period of time, they are basically immortal.

One approach to overcome immortal time bias is to do a time-dependent analysis.
Namely, we need to somehow associate the time between eligibility and treatment to the control group, and only the time between treatment and outcome (or end of follow-up) to the treatment group.
It can be done in several ways, depending on the analytical approach, like using an offset in Poisson risk-rate regression.
But one generic solution is to work in person-time data.
Basically, allow the person-time records between eligibility and treatment to be classified to the control group, and the person-time records between treatment onwards to hte treatment group.

This general solution is essentially what happens in the sequential trials.
Although the proposed solution is person-centric -- assigning the person's time to separate treatment groups -- and sequential trial is cohort-centric -- assigning a person to its appropriate group at each time step.
However, the resulting view is basically the same, as the end product is a table where that same person is classified to the control group in the period starting with its eligibility until they are assigned a treatement and move to the treatment group.

The only nuance is in how we construct the outcome in the follow-up time. 
For sequential trials to be absolutely equivalent to the person-time analysis, the control person-times should be censored at the time that person receive treatment. 
This ensures the outcome contributed to the control group is solely for the period that person is considered untreated. 
This censor-at-change is also known as a _per-protocol analysis_, where we censor individuals who deviate from their originally assigned protocol (controls who start to get teated).



### Pooling estimates vs. pooling records

## Summary
Pros and cons


show/illustrate it is equivalent to person-time in the immortal time example, only having a cohort-centric view (the person re-appears updated) rather than a person-centric view (assign time to groups). 


strategies to make efficient (deduplicate)


pool effects in meta analysis
vs pool the data from the start

"time-related biases"

keep the trial / date feature to use in multilevel things

cons, granularity is predefined