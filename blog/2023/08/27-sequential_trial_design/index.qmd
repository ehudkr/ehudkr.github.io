---
title: Sequential trial design for causal inference
subtitle: >
  Aligning time-zero TODO
author: "Ehud Karavani"
date: 2023/08/27
date-modified: last-modified
bibliography: references.bib
categories: 
  - causal inference
  - study design
---

## Introduction
I'm not special, so I've spent a lot of time addressing confounding bias.
I even created and still maintain an open-source Python package whose main focus is flexible causal inference modeling ([`pip install causallib`](https://github.com/IBM/causallib)). 
There's a place to discuss why confounding bias is the most popular bias,
but this blog post is not it.
Maybe at some other time.

Actually, there's some compelling evidence (well, at least anecdotal) that confounding bias has less of a biasing effect than what one would expect.
One example is @garcia2017value
examining the effect of colorectal cancer screening on colorectal cancer incidence.
It showed the same survival curves for treatment and control units
when adjusting and not adjusting for confounding factors.
This, in and of itself, is a poor evidence, 
but the exact same shape of survival curves also appeared in @bretthauer2022effect,
an RCT examing the exact same question.
This suggests that confounding bias did not affect the observational study.[^1]

[^1]: A similar phenomenon was also observed in @hernan2008observational,
finding similar hazard ratios (in terms of point estimation and confidence intervals) between adjusted and unadjusted estimates, 
suggesting the cause of discrepency between previous observational studies (even using the same data as they did) and RCTs was not confounding bias but rather the mysterious bias which is the subject of this blog post.

### I have _zero_ time for this bias
This bias originates from improperly setting the _time-zero_.
Time zero (or "index date") is the point in time which splits the baseline period from the follow-up period.
History from future, retrospectively speaking.
It usually the time in which treatment is initiated, 
and therefore the point in time from which we look backward to obtain historical data (baseline covariates) 
and look forward to gather follow-up data (outcomes).  
As such, to properly set up time zero, three things must align:

1. The subject must meet the eligibility criteria
1. "Treatment" must be assigned
1. Outcomes are beginning to be counted. 

Learning causal inference, we are used to getting datasets with nice and percise binary treatment variables and covariates.
But where did these come from?
People's lives are not cross sectional, they are a trajectory through time.
So there are lots of design decisions in order to squeeze all of it into tabular form.
Having longitudinal data makes it more possible, but not more easy.
How do we decide how to assign a person into either treatment groups (or not at all if not eligible).

Given this presentation, you might see why active-comparator designs are so appealing.
It is more straightforward to compare to active treatments head-to-head,
since we just define the first treatment initiation of each drug (the two groups) as our time zero.

The trickier part is when we want to design a study to compare treatment initators with _non-users_.
This is often of interest in pragmatic trials.
What is the index date for someone who just lived their life never getting treated?
Non-initators have no point in time where they start treatment,
making it harder to align this non-existing "treatment assignment" to the follow-up and eligibilty. 

This often leads to comparing either persistent users
or those who taken the drug at some time (i.e., _all_ or _any_), 
to those who never used it.
This study design does very little in informing physicians how to act on the patient they are currently facing.
_"Take this drug and if you survive the next 5 years (i.e., become a persistent user),_ 
_then you will reduce your risk by x percent"_ 
does not inspire much confidence 
and is not very helpful for the patient who is living now in the present and not five years into the future.[^2]

[^2]: Furthermore, I believe this discrepancy in how to define treatment groups, 
namely, how to define the $1$ and $0$ in $Y^1$ and $Y^0$, 
boils down to the causal consistency assumptions.
Defining a poor treatment mechanism in the study design means the outcome one observes in their data ($E[Y|A=a]$) will not equal the hypothetical outcome they care about ($E[Y^a]$).

## Sequential trial design
So how can we force the alignment of eligibility, treatment initiation, and follow-up into a proper time zero?

### A single "sequential" trial

One simple approach is to use calendar time. 
Set the time-zero to a specific date.
Say, for instance, January 1st, 2020.
This will be the point in time splitting history from future.
Keep whoever is eligibile to participate at this date, discard the rest;
data from before this date are the baseline covariates;
data from this date forward is the follow-up;
and whoever got treated on this date is considered in the treatment group, the rest are controls.

Individuals treated before January 1st are probably ineligible 
(most study designs might enforce participants to be treatment naive).
Individuals treated after January 1st are considered controls,
because time-zero is set at January 1st, not the future.
Though a per-protocol analysis might decide to censor them from follow-up because they deviated from their original (control) assignment.
This creates a design that answers a question of treat now vs. don't treat now (but possible treat later).

However, this single trial is too naive and not very efficient.
We miss all the treated individuals in the past and in the future.
There might even not be anyone treated on January 1st. 
We throw away a lot of information. 
That's a big blow to statistical power.

### A sequence of sequential trials

Therefore, a natural extension would be to just repeat the process.
Repeat it for January 2nd, 2020, for January 3rd, 2020, for January 4th, and so forth.
For each time point we:
1. Consider whoever meets the eligibility criteria and discard the rest,
1. Set the treatment indicator based on who got treated,
1. Extract baseline covariates prior to that time point,
1. Extract outcome information from that time onwards. 

The way I imagine this process is that we have stencil-like mold, 
defined by our eligibility criteria,
from which we funnel observations like a strainer.
We go to January 1st, put the stencil-strainer, shake the database and filter only eligible individuals at the time. 
We then go to January 2nd, filter; 
and so on and so forth,
rinse and repeat.
A moving window through time, only that window is specially shaped by the eligibilty criteria. 

This means a single person can have multiple records (entries, or rows) in the dataset.
One for each trial (time-zero).

We can see this illustrated below with a person's timeline and its corresponding person-time tabular form.
In this study design, baseline covariates are taken 4 time steps relative to time-zero (e.g., 2 years prior to time-zero), 
and follow-up is taken 4 time steps starting time zero (e.g., outcome within 2 years).
Thus, the covariate profile changes as time-zero progresses.
At times 4-7, üèä‚Äç‚ôÇÔ∏è is included as it is within the baseline period dictated by the study design, but it is no longer counted in time 8.
Similarly, the outcome üöë is not observed at time 4, only starting at time 5.[^3]
To make things more explicitly, I also indicate eligibility; 
in this example, the study design requires participant to no been treated in the last 4 time-steps (treatment-naive), 
and so at times 7 and 8 the person is no longer eligibile as they were treated in time 6.[^4] 

![An illustration of a person timeline and how its corrsponding person-time tabular form. It shows multiple time-zeros set from time 4 throughout time 8 (think Jan 1st to Jan 4th from above). Different time-zeros have different covariate (üèä‚Äç‚ôÇÔ∏è) profile, different outcome (üöë) based on the moving follow-up window, and - although that person is treated (üíä) - they are not always considered as such.](single_person_time_moving_window.png)


[^3]: In time-to-event settings, the follow-up window is often as long as can be possibly observed, avoiding explicitly stating a follow-up timeframe.
In such scenarios, we can see the time to outcome (üöë) decreases as time-zero progresses.
![](single_person_time_moving_window_survival.png)

[^4]: First, note that they might also be inelgible because they don't have sufficient follow-up. 
Second, that person may also be ineligible at time 10 as they are no longer outcome-naive, too.



Illustrate the process
footnote: nested trials (because whoever considered for next time point is fromthe controls. treatment naive)


show/illustrate it is equivalent to person-time in the immortal time example, only having a cohort-centric view (the person re-appears updated) rather than a person-centric view (assign time to groups). 


strategies to make efficient (deduplicate)


pool effects in meta analysis
vs pool the data from the start

"time-related biases"

keep the trial / date feature to use in multilevel things

cons, granularity is predefined