---
title: "Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation"
date: 2025-05-03
doi: https://proceedings.mlr.press/v258/ter-minassian25a.html
author:
  - name: Lucile Tar-Minassian
    affiliations:
      - ref: ibmrisrl
      - ref: oxfordstats
  - name: Liran Szlak
    affiliations:
      - ref: ibmrisrl
  - name: Ehud Karavani 
    affiliations:
      - ref: ibmrisrl
  - name: Chris Holmes 
    affiliations:
      - ref: oxfordstats
  - name: Yishai Shimoni
    affiliations: 
      - ref: ibmrisrl
affiliations: 
  - id: ibmrisrl
    name: IBM Research
    # organization: IBM Research
    country: Israel
    department: Causal Machine Learning for Healthcare and Life Sciences
  - id: oxfordstats
    name: University of Oxford
    country: UK
    department: Department of Statistics
categories:
  - causal inference
  - methods
# keywords: 
publication: "AISTATS"
journal: 
  title: "AISTATS"
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/ter-minassian25a/ter-minassian25a.pdf
abstract: >
  Interpretability and transparency are essential for incorporating causal effect models from observational data into policy decision-making. 
  They can provide trust for the model in the absence of ground truth labels to evaluate the accuracy of such models. 
  To date, attempts at transparent causal effect estimation consist of applying post hoc explanation methods to black-box models, which are not interpretable. 
  Here, we present BICauseTree: an interpretable balancing method that identifies clusters where natural experiments occur locally. 
  Our approach builds on decision trees with a customized objective function to improve balancing and reduce treatment allocation bias. 
  Consequently, it can additionally detect subgroups presenting positivity violations, exclude them, and provide a covariate-based definition of the target population we can infer from and generalize to. 
  We evaluate the method's performance using synthetic and realistic datasets, explore its bias-interpretability tradeoff, and show that it is comparable with existing approaches
description: >
  A tree-based method for stratifying data while optimizing for balancing in order to obtain interpretable effect estimations and abstention in non-overlapping regions.
---

:::{.column-page layout-ncol=2}

![](bias.png)

![](depth_over_bias.png)

:::

| PMLR: [https://proceedings.mlr.press/v258/ter-minassian25a.html](https://proceedings.mlr.press/v258/ter-minassian25a.html)  
| OpenReview: [https://openreview.net/forum?id=WdcA7v7uzc](https://openreview.net/forum?id=WdcA7v7uzc)  
| PDF: [https://raw.githubusercontent.com/mlresearch/v258/main/assets/ter-minassian25a/ter-minassian25a.pdf](https://raw.githubusercontent.com/mlresearch/v258/main/assets/ter-minassian25a/ter-minassian25a.pdf)



## Citation
```bibtex
@inproceedings{ter-minassian2025hierarchical,
  title={Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation},
  author={Ter-Minassian, Lucile and Szlak, Liran and Karavani, Ehud and Holmes, Christopher C. and Shimoni, Yishai},
  booktitle={The 28th International Conference on Artificial Intelligence and Statistics},
  year={2025},
  series={Proceedings of Machine Learning Research},
  publisher={PMLR},
  pdf={https://raw.githubusercontent.com/mlresearch/v258/main/assets/ter-minassian25a/ter-minassian25a.pdf},
  url={https://proceedings.mlr.press/v258/ter-minassian25a.html},
}
```
 <!-- url={https://openreview.net/forum?id=WdcA7v7uzc} -->

